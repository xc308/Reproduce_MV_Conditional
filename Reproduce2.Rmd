---
title: "Reproduce_conditional2"
author: "XC"
date: "27/09/2021"
output:
  pdf_document:
    fig_caption: yes
csl: apa.csl
Extension: raw_tex
---
### what is \newcommand ?
ref: https://stackoverflow.com/questions/41655383/r-markdown-similar-feature-to-newcommand-in-latex

\newcommand{\Deltab} {\Delta} 
\newcommand{\intd} {\textrm{d}}
\newcommand{\Bmat} {B}
\newcommand{\Cmat} {C}
\newcommand{\cmat} {c}
\newcommand{\Imat} {I}
\newcommand{\bvec} {b}
\newcommand{\svec} {s}
\newcommand{\uvec} {u}
\newcommand{\omegab} {\omega}
\newcommand{\s}{s}
\newcommand{\h}{h}
\renewcommand{\b}{b}
\newcommand{\e}{e}
\newcommand{\z}{z}
\renewcommand{\v}{v}
\renewcommand{\u}{u}
\newcommand{\w}{w}
\renewcommand{\d}{d}
\newcommand{\Z}{Z}
\newcommand{\x}{x}
\newcommand{\Y}{Y}
\newcommand{\Yvec} {Y}
\newcommand{\Zvec}{Z}
\newcommand{\epsilonb}{\varepsilon}
\newcommand{bI} {I}
\newcommand{\bB}{B}
\newcommand{\bbeta}{\beta}
\newcommand{\bzero}{0}
\newcommand{\bSigma}{\Sigma}
\newcommand{\E}{E}
\newcommand{\cov} {\mathrm{cov}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\vect}{\mathrm{vec}}
\newcommand{\Gau}{\mathrm{Gau}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\T}{{ \mathrm{\scriptscriptstyle T} }}

\renewcommand{\figurename}{Fig.}


## Setting up

```{r}
#install.packages("devtools")
#library(devtools)
#install_github("andrewzm/bicon") 
```

```{r, message=FALSE}

# INLA
#install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(INLA)
```

```{r}
# For core operation
library(Matrix)
library(dplyr)
library(tidyr)
```

```{r}
# for plotting and for arranging the figures into panels for publication
library(ggplot2)
library(gridExtra)
library(grid)
#install.packages("extrafont")
library(extrafont)
```

```{r}
# provides the data
#install.packages("maptools")
library(maptools)

#install.packages("mapproj")
library(mapproj)

library(RandomFields)
```

```{r}
# contains a handy routing for computing CRPSs, crps: Continuous Ranked Probability Score

#install.packages("verification")
library(verification)
```

```{r}
# for parallel operations we will be requiring `foreach` and `doParallel`
#install.packages("foreach")
library(foreach)
library(doParallel)
```

Example below consider four models that vary only through the interaction function $b_o(h)$. The models are

\begin{equation*}
\begin{array}{ll}
\textrm{Model 1 (independent Mat{\'e}rns):} &b_o(\h) \equiv 0, \\
\textrm{Model 2 (pointwise dependence):} &b_o(\h) \equiv A\delta(\h), \\
\textrm{Model 3 (diffused dependence):} & \textrm{Model 4 with~} \Deltab = 0 \\
\textrm{Model 4 (asymmetric dependence):} &b_o(\h) \equiv \left\{\begin{array}{ll} A\{1 - (\|\h - \Deltab\|/r)^2\}^2, & \| \h - \Deltab\| \le r \\ 0, & \textrm{otherwise}, \end{array} \right. 
\end{array}
\end{equation*}

where $\Deltab = (\Delta_1, \Delta_2)^\T$ is a shift-parameter vector that captures asymmetry, 
  $r$ is the aperture parameter, 
  and $A$ is a scaling parameter. 
  In Models 3 and 4, $b_o(\h)$ is a shifted bisquare function defined on $\mathbb{R}^2$. 
  The covariance functions $C_{11}(\cdot)$ and $C_{2|1}(\cdot)$ are Matérn covariance functions. 
  For each model we also consider a \emph{reversed} dependence, where we switch $Y_2$ and $Y_1$. This gives us a total of eight models to fit and compare.
  
  

First, set program options, indicating which parts of the program we want to run and which parts we want to skip

```{r}
### Model choice
model_names <- c("independent","pointwise","moving_average_delta0","moving_average")
# img_path <- "../paper/art"                  ## Where to save the figures
show_figs <- 1                              ## Show the figures in document
print_figs <- 0                             ## Print figures to file (leave =0)
LK_analysis <- 0                            ## Carry out likelihood analysis
LOO_analysis <- 0                           ## Carry out LOO analysis
Shifted_Pars_estimation <- 0                ## Fit shifted parsimonious Matern
RF_estimation <- 0                          ## Carry out LOO with RFields
useMPI <- 0                                 ## MPI backend available?
```


## The data
```{r,eval=TRUE}
data(weather,package = "RandomFields")
weather <- weather %>% data.frame()
print(head(weather))
```
The `weather` table contains four fields, with latitude, longitude, `pressure forecasting errors`, and `temperature forecasting errors` for December 13, 2003 at 4 p.m. in the North American Pacific Northwest.


Since pressure and temperature have different units, we find a scaling factor by taking the ratio of the sample variances of the two variates, and computing its square root. use this factor to scale the pressure variable


```{r}
p_scale <- var(weather$pressure) / var(weather$temperature) %>%
  sqrt() %>%
  as.numeric()

```


A function `form_Z` extract $Z_1$ and $Z_2$ and concatenate them into one long vector $Z$. If model number is > 4, then vectors $Z_1$ and $Z_2$ are inverted.

Also define `m1` as the number of observations of $Y_1$, `m2` as the number of observations of $Y_2$ and `m` as the total number of observations.

```{r}
form_Z <- function(model_num, scale = T) {
  Z1 <- weather$temperature
  Z2 <- weather$pressure
  
  if (scale) Z2 <- Z2 / p_scale   # scale press
  
  if (model_num > 4) {
     temp <- Z1
     Z1 <- Z2
     Z2 <- temp                   # reverse Z1, Z2 
  }
  Z <- rbind(Z1, Z2)
}

m1 <- m2 <- nrow(weather)        # Numb of obs of Y1, Y2
m  <- m1 + m2                    # total numb of obs
I_m1 <- diag(m1)                 # Identity matrix of m1 by m1
```


## Process discretisation

approximate the processes as a sum of elemental basis functions (tent functions) constructed on a triangulation.

The triangulation is formed using the mesher in the `INLA` package

provide a tailored function in the package `bicon`, `initFEbasis`, 
which takes information from the `INLA` mesher and casts it into a `Mesh` object

Importantly, the `Mesh` object also contains information on the areas of the 
elements in the Voronoi tesselation, which will be used to approximate the integrations.

```{r}
## Constructing mesh
##------------------

mesh <- inla.mesh.2d(loc = weather[c("lon", "lat")], 
             cutoff = 0, max.edge = 0.75, offset = 4)  # fine mesh
# Create a triangle mesh based on initial point locations


mesh_locs <- mesh$loc[, 1:2]     # in 2-D, only need lon, lat of the nodes


#str(mesh)
# $ n       : int 2071
# $ loc     : num [1:2071, 1:3] -130 -114 -111 -111 -114 ...
# $ graph   :List of 5
#  ..$ tv : int [1:3982, 1:3] 289 157 162 658 172 1275 336 1613 9 165 ...
#  ..$ vt : int [1:2071, 1] 2619 1734 3559 3375 3629 1738 3413 2356 2165 202 ...
#  ..$ tt : int [1:3982, 1:3] 2967 3869 461 3041 69 2399 3314 208 2705 22 ...
#  ..$ tti: int [1:3982, 1:3] 1 1 1 1 2 2 1 1 1 2 ...
#  ..$ vv :Formal class 'dgTMatrix' [package "Matrix"] with 6 slots
#  .. .. ..@ i       : int [1:12104] 1208 1238 1378 911 1046 1117 847 848 1943 1073 ...
#  .. .. ..@ j       : int [1:12104] 0 0 0 1 1 1 2 2 2 3 ...
#  .. .. ..@ Dim     : int [1:2] 2071 2071
#  .. .. ..@ x       : num [1:12104] 1 1 1 1 1 1 1 1 1 1 ...

```

```{r}
head(mesh_locs)
str(mesh_locs)
# num [1:2071, 1:2]
```

```{r}
head(as.matrix(mesh_locs))
str(as.matrix(mesh_locs))  # num [1:2071, 1:2]
```


```{r}
## Compute distances as in Gneiting (2010) 
# -- great circle distances
##---------------------------------------------

# str(RFearth2dist(coord = as.matrix(mesh_locs)))
# calculates distances, cf. dist, assuming that the earth is an ellipsoid

# Angle mode switches to 'degree'.
#  'dist' num [1:2143485] 1373 1662 2264 2387 2087 ...

D <- as.matrix(RFearth2dist(coord = as.matrix(mesh_locs)))

str(D)  # num [1:2071, 1:2071] 0 1373 1662 2264 2387
 
```

```{r}
str(c(D))  #  # 2071 * 2071 = 4289041
# num [1:4289041] 0 1373 1662 2264 2387 ...
Dvec <- as.double(c(D))
```


```{r}
Dobs <- as.matrix(RFearth2dist(coord = as.matrix(weather[c("lon", "lat")])))
str(Dobs) # num [1:157, 1:157] 0 697 502 502 532 ..
Dobs_vec <- as.double(c(Dobs))

```


Below is optional
```{r}
## Cast into custom Mesh object (optional) 
##-----------------------------

#install.packages("initFEbasis")
#library(initFEbasis)
#Mesh <- initFEbasis(p = mesh_locs,        # n * 2 matrix of vertex locations
#            t = mesh$graph$tv,     # m * 3 matix of triangulation; each row identify which row of p to make up construction
#            K = mesh$graph$vv     # connection matrix 
#)

```
?initFEbasis: 
initialise a finite element basis which initialises an object of class FEBasis which defines a set of elemental ‘tent’ basis functions over a pre-specified triangulation in 2-D


```{r}
#str(Mesh)
#$ vars:'data.frame':	2071 obs. of  4 variables:
#  .. .. ..$ x        : num [1:2071] -130 -114 -111 -111 -114 ...
#  .. .. ..$ y        : num [1:2071] 36.8 36.8 40.1 52.6 55.7 ...
#  .. .. ..$ n        : int [1:2071] 1 2 3 4 5 6 7 8 9 10 ...
#  .. .. ..$ area_tess: num [1:2071] 0.112 0.137 0.146 0.128 0.111 ...
```


Alternative to Mesh obj of FEbasis package, we could use `deldir` package to 1. construct Voronoi tesselation from INLA mesh points; 2. from the output summary, extract the tessaltion area directly. 

```{r}
#install.packages("deldir")
library(deldir)

Voroni <- deldir(x = mesh_locs[, 1], 
       y = mesh_locs[, 2], 
       rw = c(min(mesh_locs[, 1]) - 0.00001,
              max(mesh_locs[, 1]) + 0.00001,
              min(mesh_locs[, 2]) - 0.00001,
              max(mesh_locs[, 2]) + 0.00001))

str(Voroni)

Area.tess <- Voroni$summary$dir.area
```



Next establish the dimension of our grids. 
Since we will be evaluating $Y_1$ and $Y_2$ on the same grid, `n1` = `n2`
```{r}
## Mesh Size
##-----------

n2 <- n1 <- nrow(mesh_locs)
n = n1 + n2
```


Will approximate the integration using the rectangular rule. 
When using finite elements, this reduces to using the areas of the Voronoi tessellation as integration weights.

We first compute the vector of displacements $h$ which will be of length (`n2` $\times$ `n1`).

Then, with each element we associate an integration weight equal to the area of the Voronoi tessellation of the element.


```{r}
str(mesh_locs)
str(mesh_locs[1, ])   # vector
str(t(mesh_locs) - mesh_locs[1, ])  
# num [1:2, 1:2071] 0.00 0.00 1.55e+01 

head(t(t(mesh_locs) - mesh_locs[1, ]))
```


```{r}
# Mesh Integration points
#-------------------------

h <- matrix(0, n1 * n2, ncol = 2)
Area <- rep(0, n1 * n2)
for (i in 1:n1) {
  h[((i - 1) * n1 + 1) : (i * n1), ] <- t(t(mesh_locs) - mesh_locs[i])
  Area[((i - 1) * n1 + 1) : (i * n1) ] <- Area.tess

}

str(h) # num [1:4289041, 1:2]

h1_double <- as.double(h[, 1])
h2_double <- as.double(h[, 2])
str(h1_double)
```



## Organizing the Observations
Map process to observations by constructing an incidence matrix, 
which is `1` if obs conincides with a vertex of triangualtion mesh, and `0` otherwise. 

Dimension of the whole incidence matrix is  (`m1` + `m2`) $\times$ (`n1` + `n2`), where `m1 <- m2<- nrow(weather)` 

Since in this problem we have co-located observations, we find the incidence matrix for one of the observations, $Z_1$, and then form the whole incidence matrix by simply constructing a block diagonal matrix (using `bdiag`). 

We use `left_join` to find the tri grid vertex with which obs location coincide, which returns `NA` if no coincides with vertex. 


```{r}
mesh_locs <- data.frame(lon = mesh_locs[, 1], lat = mesh_locs[, 2])
#head(left_join(x = mesh_locs, y = weather))
idx <- which(!is.na(left_join(x = mesh_locs, y = weather)$temperature))

str(idx)  # int [1:157] 9 10 11 12 13 14 15 16 17 18 ...

C1 <- sparseMatrix(i = 1:m1, j = idx, x = 1, dims = c(m1, n1)) # incidence matrix
C <- bdiag(C1, C1)  # total incidence matrix

str(C)
```



## Maximum likelihood estimation

Since the optimisation algorithm requires a parameter vector of the same length (irrespective of the model number) 

we first define a function `append_theta` that takes the parameter vector associated with the model in question and appends it so it is of the required size (in this case of length 12).

M1(M5): append 4 0's, M2(M6): append 3 0's, M3(M7): append 2 0's; 

```{r}

append_theta <- function(theta, model_num) {
  if (model_num %in% c(1, 5)) {  # M1 and M5
    theta <- c(theta, rep(0, 4))
    #theta[10] <- 0.001
  } else if (model_num %in% c(2, 6)) {
    theta <- c(theta, rep(0, 3))
    theta[10] <- 0.001
  } else if (model_num %in% c(3, 7)) {
    theta <- c(theta, rep(0, 2))
  } 
  theta
}
```


Next, we require a function that, given the parameter vector `theta` and the model number `model_num`, returns the required matrices and vectors used in fitting. These are the matrices
\begin{equation}\label{eqn:cov-matrix}
\textrm{\texttt{SY}} =  \begin{bmatrix}\bSigma_{11} & \bSigma_{11}\bB^\T \\ \bB \bSigma_{11} & \bSigma_{2\mid 1}+\bB\bSigma_{11}\bB^\T \end{bmatrix}, ~~\qquad \textrm{\texttt{So}} =  \begin{bmatrix}\tau_1^2I_m  & 0\\ 0 & \tau_2^2I_m  \end{bmatrix}.                                
\end{equation}

We then add these two together to obtain the matrix $\textrm{cov}((\Yvec_1^\T,\Yvec_2^\T)^\T)$ which, recall that for this example is identical to $\textrm{cov}((\Zvec_1^\T,\Zvec_2^\T)^\T)$ since the data is equal to the process at the observed locations. 

If `whole_mesh` is `TRUE`, then the process covariance matrix is evaluated over the entire mesh (used for cokriging at unobserved locations).


```{r}
str(h)  # num [1:4289041, 1:2]

source("bisq_fn(2d_B).R")

if (model_num %in% c(3, 4, 7, 8)) {
  B <- bisq_B(h, delta = theta[11:12], r =  theta[10], 
              A = theta[9], area = Area, 
              n1 = n1, n2 = n2)  #  num [1:2071, 1:2071]  proc lvl
}

str(C1)  # @ Dim     : int [1:2] 157 2071

C1B <- C1 %*% B  # obs * proc %*% proc * proc = obs * proc
```


```{r}
## Form matrices (scaled pressure)

source("make_cov_fn.R")

# obs level 157
C11 <- makeC(Dobs_vec, Var = theta[3], Kappa = theta[5], nu = theta[7])  # obs
C2_1 <- makeC(Dobs_vec, Var = theta[4], Kappa = theta[6], nu = theta[8]) # obs


if (Model_num %in% c(3, 4, 7, 8) | whole_mesh == T) {
  C11_proc <- makeC(Dvec, Var = theta[3], Kappa = theta[5], nu = theta[7])
  C12 <- C1B %*% C11_proc %*% t(C1)    # obs * obs
  C21 <- t(C12)
  C22 <- C2_1 + forceSymmetric(C1B %*% forceSymmetric(C11_proc) %*% t(C1B))
} else {
  C21 <- C12 <- C11 * theta[9]
  C22 <- C2_1 + C11 * theta[9]^2
}


# grid level 2071
if (whole_mesh == T) {
  C11 <- C11_proc
  C2_1_proc <- makeC(Dvec, Var = theta[4], Kappa = theta[6], nu = theta[8]) 
  C21 <- C11 %*% B
  C12 <- t(C21)
  C22 <- C2_1_proc + crossprod(chol(C11) %*% t(B))
}



## Form matrices (Unscaled pressure)
C22_true <- ifelse(Model_num < 5, 1/p_scale^2, 1) * C22
C11_true <- ifelse(Model_num > 4, 1/p_scale^2, 1) * C11
C12_true <- C12 * p_scale
C21_true <- C21 * p_scale

CY_true <- rbind(cbind(C11_true, C12_true), cbind(C21_true, C22_true)) %>% as("dgeMatrix")


# ref
#m1 <- m2 <- nrow(weather)        # Numb of obs of Y1, Y2
#m  <- m1 + m2                    # total numb of obs
#I_m1 <- diag(m1)                 # Identity matrix of m1 by m1

I_m1 <- diag(m1)
Co_true <- bdiag(ifelse(model_num < 5, 1, 1/p_scale^2) * theta[1] * I_m1, 
      ifelse(model_num < 5, 1/p_scale^2, 1) * theta[2] * I_m1)   
        # only scale theta[2],as it's related to press

if (whole_mesh == T) t(C) %*% Co_true %*% C   # proc level

list(CY = CY_true, Co = Co_true, Z = form_Z(model_num, scale = F))

```


```{r}
# ref
form_Z <- function(model_num, scale = T) {
  Z1 <- weather$temperature
  Z2 <- weather$pressure
  
  if (scale) Z2 <- Z2 / p_scale   # scale press
  
  if (model_num > 4) {
     temp <- Z1
     Z1 <- Z2
     Z2 <- temp                   # reverse Z1, Z2 
  }
  Z <- rbind(Z1, Z2)
}
```



```{r} 
# ref
h <- matrix(0, n1 * n2, 2)
areas <- rep(0, n1 * n2)
for (i in 1:n2) {
  h[((i - 1) * n1 + 1):(i * n1), ] <- t(t(mesh_locs) - mesh_locs[i, ])
  areas[((i - 1) * n1 + 1):(i * n1)] <- Mesh["area_tess"]
}
```


```{r}
# now put above into one function
construct_mat <- function(theta, model_num, scale = F) {
  
  if (model_num %in% c(3, 4, 7, 8)) {
    str(h)  # num [1:4289041, 1:2]

    source("bisq_fn(2d_B).R")
    B <- bisq_B(h, delta = theta[11:12], r =  theta[10],   # h is ready above
              A = theta[9], area = Area, 
              n1 = n1, n2 = n2)  #  num [1:2071, 1:2071]  proc lvl
    
  }
    
  str(C1)  # @ Dim     : int [1:2] 157 2071
  C1B <- C1 %*% B  # obs * proc %*% proc * proc = obs * proc
  
  
  
  ## Form matrices (scaled pressure)
  source("make_cov_fn.R")
  
  # obs level 157
  C11 <- makeC(Dobs_vec, Var = theta[3], Kappa = theta[5], nu = theta[7])  # obs
  C2_1 <- makeC(Dobs_vec, Var = theta[4], Kappa = theta[6], nu = theta[8]) # obs
  
      # link btw obs and proc  
  if (Model_num %in% c(3, 4, 7, 8) | whole_mesh == T) {
    C11_proc <- makeC(Dvec, Var = theta[3], Kappa = theta[5], nu = theta[7])
    C12 <- C1B %*% C11_proc %*% t(C1)    # obs * obs
    C21 <- t(C12)
    C22 <- C2_1 + forceSymmetric(C1B %*% forceSymmetric(C11_proc) %*% t(C1B))
  } else {
    C21 <- C12 <- C11 * theta[9]
    C22 <- C2_1 + C11 * theta[9]^2
  }
  
  
  # grid level 2071
  if (whole_mesh == T) {
    S11 <- S11_big       # proc lvl
    S12 <- B %*% S11     # proc lvl
    S21 <- t(S12)
    S22 <- S2_1 %*% C1  + crossprod(chol(S11) %*% t(B))
  }
  
  
  ## Form matrices (Unscaled pressure)
  C22_true <- ifelse(Model_num < 5, 1/p_scale^2, 1) * C22
  C11_true <- ifelse(Model_num > 4, 1/p_scale^2, 1) * C11
  C12_true <- C12 / p_scale
  C21_true <- C21 / p_scale
  
  CY_true <- rbind(cbind(C11_true, C12_true), cbind(C21_true, C22_true)) %>% as("dgeMatrix")

  
  ## So
  I_m1 <- Imat(m1)  # Imat <- function(n) sparseMatrix(i = 1:n, j = 1:n, x = 1)
  Co_true <- bdiag(ifelse(model_num < 5, 1, 1/p_scale^2) * theta[1] * I_m1, 
      ifelse(model_num < 5, 1/p_scale^2, 1) * theta[2] * I_m1)   
        # only scale theta[2],as it's related to press

  if (whole_mesh == T) t(C) %*% Co_true %*% C   # proc level

  list(CY = CY_true, Co = Co_true, Z = form_Z(model_num, scale = F))
}

```


## Loglik
- Now define the log-liklihood function:
  - The joint distribution of [Z1, Z2] ~ Gau(\bzero, \bSigma_Z), where the \bSigma_Z = CY + Co. 
  - So the logLik = -(d/2) * log(2pi) - 1/2 * log(det(\bSigma_Z)) - 1/2 * t(Z) * \bSigma_Z^(-1) * Z.

- To allow CV, drop certain obs: 
  - The indices to be dropped is stored in `i`, and if no obs drop, then `i = NULL`. 
  

```{r}

Loglik_Model <- function(theta, model_num, i = NULL) {

  # theta1 <- sigma2e1
  # theta2 <- sigma2e2
  # theta3 <- sigma211
  # theta4 <- sigma22_1
  # theta5 <- kappa11
  # theta6 <- kappa2_1
  # theta7 <- nu11
  # theta8 <- nu2_1
  # theta9 <- A
  # theta10 <- r
  # theta11 <- delta1
  # theta12 <- delta2
  
  
  ## append theta M1(5):append 4 0's, M2(6): append 3 0's, M3(7): append 2 0's
  theta <- append_theta(theta, model_num)
  
  
  ## hard constraint on parameters
  if (theta[1] <= 0 | theta[2] <= 0 | theta[3] <= 0 | theta[4] <= 0 |
      theta[5] <= 0.001 | theta[6] <= 0.001 |theta[7] <= 0.05 | theta[8] <= 0.05 |
      theta[10] <= 0.0005) {
          return(Inf) 
  } else {
    ## Construct Matrices
    X <- construct_mat(theta, model_num, scale = F)
    
    
    ## drop obs to CV
    if(is.null(i)) {
      CY <- X$CY
      Co <- X$Co
      Z <- X$Z
    } else {
      CY <- X$CY[-i, -i]
      Co <- X$Co[-i, -i]
      Z <- X$Z[-i, , drop = F]
    }
  
    ## Evaluate log-lik function
    cholYo <- chol(CY + Co)
    log_lik <- -(-0.5 * nrow(Z) * log(2 * pi) 
    - 0.5 * logdet(cholYo) 
    - 0.5 * t(Z) %*% chol2inv(cholYo) %*% Z) %>% as.numeric()
    
    return(log_lik)
  
  }
}
```


## Optimization 
  - For optimization, use `optim` (BFGS) function; 
  - 3000 iterations and set `trace = 6` for detailed output;
  - not to compute the Hessian as this is not required as not in our analysis;
  - parameter `i` indicate if the ith obs is involved in the fit, 
      and if i = NULL, all obs are included. 
  - the function `optim_loglik` is called for each model later on
  
  
```{r}  
optim_loglik <- function(par, model_num, i = NULL) {
  optim(par = par, 
        fn = Loglik_Model,
        model_num = model_num,
        i = i, 
        hessian = F,
        control = list(trace = 6, 
                       pgtol = 0, 
                       parscale = rep(0.1, length(par)), # par/parscale
                       maxit = 3000))
}  

```













